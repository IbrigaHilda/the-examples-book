# Projects {#projects}

## Templates

### R & Bash

[Template](https://raw.githubusercontent.com/TheDataMine/the-examples-book/master/files/r_bash_project_template.Rmd)

Students in STAT 19000, 29000, and 39000 are to use this as a template for non-python project solutions. All code should live inside code chunks with the proper language code (r, bash, sql, etc.). Every question should be clearly marked with a third-level header (using 3 "#"'s). Sections for question solutions should be added or removed based on the number of questions in the given project. All code chunks are to be run and solutions displayed prior to submission.

Any format or template related questions should be asked in Piazza.

### Python

[Template](https://raw.githubusercontent.com/TheDataMine/the-examples-book/master/files/python_project_template.ipynb)

Students in STAT 19000, 29000, and 39000 are to use this as a template for python project solutions. Every question should be clearly marked with a second-level header (using 3 "#"'s) in a Markdown cell. Sections for question solutions should be added or removed based on the number of questions in the given project. All cells are to be run and solutions displayed prior to submission.

Any format or template related questions should be asked in Piazza.


## STAT 19000

## STAT 29000

### Project 2

---

**Motivation:** The ability to quickly reproduce an analysis is important. It is often necessary that other individuals will need to be able to understand and reproduce an analysis. This concept is so important there are classes solely on reproducible research! In fact, there are papers that investigate and highlight the lack of reproducibility in various fields. If you are interested in reading about this topic, a good place to start is the paper titled ["Why Most Published Research Findings Are False"](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124), by John Ioannidis (2005). 

**Context:** Making your work reproducible is extremely important. We will focus on the computational part of reproducibility. We will learn RMarkdown to document your analyses so others can easily understand and reproduce the computations that led to your conclusions. Pay close attention as future project templates will be RMarkdown templates.

**Scope:** Understand Markdown, RMarkdown, and how to use it to make your data analysis reproducible.

**Learning objectives:**

```{block, type="bbox"}
- Use Markdown syntax within an Rmarkdown document to achieve various text transformations.
- Use RMarkdown code chunks to display and/or run snippets of code.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

##### 1. Make the following text (including the asterisks) bold: `This needs to be **very** bold`. Make the following text (including the underscores) italicized: `This needs to be _very_ italicized.`

**Hint:** *Try mixing and matching ways to embolden or italicize text. Alternatively, look up "escaping characters in markdown", or see [here](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters).*

**Hint:** *Be sure to check out the [Rmarkdown Cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) and our section on [Rmarkdown in the book](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown).*

**Note:** *Rmarkdown is essentially Markdown + the ability to run and display code chunks. In this question, we are actually using Markdown within Rmarkdown!*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [escaping characters](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters)*

```{block, type="bbox"}
**Item(s) to submit:**

- Fill in the chunk under (1) in the `stat29000project02template.Rmd` file with 2 lines of markdown text. Note that when compiled, this text will be unmodified, regular text.
```

##### 2. Create an unordered list of your top 3 favorite academic interests (some examples could include: machine learning, operating systems, forensic accounting, etc.). Create another *ordered* list that ranks your academic interests in order of most interested to least interested.

**Hint:** *You can learn what ordered and unordered lists are [here]( https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf).*

**Note:** *Similar to (1a), in this question we are dealing with Markdown. If we were to copy and paste the solution to this problem in a Markdown editor, it would be the same result as when we Knit it here.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the lists under (2) in the `stat29000project02template.Rmd` file. Note that when compiled, this text will appear as nice, formatted lists.
```

##### 3. Browse https://www.linkedin.com/ and read some profiles. Pay special attention to accounts with an "About" section. Write your own personal "About" section using Markdown. Include the following:

- A header (your choice of size) that says "About".
- A horizontal rule directly underlining the header.
- The text of your personal "About" section that you would feel comfortable uploading to linkedin, including at least 1 link.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the described profile under (3) in the `stat29000project02template.Rmd` file.
```

##### 4. Your co-worker wrote a report, and has asked you to beautify it. Knowing Rmarkdown, you agreed. Spruce up the report found under (4) in `stat29000project02template.Rmd`. At a minimum:

- Make the title pronounced.
- Make all links appear as a word or words, rather than the long-form URL.
- Organize all code into code chunks where code and output are displayed. If the output is really long, just display the code.
- Make the calls to the `library` function and the `install.packages` function be evaluated but not displayed. Make sure all warnings and errors that may eventually occur, do not appear in the final document.

Feel free to make any other changes that make the report more visually pleasing.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Spruce up the "document" under (4) in the `stat29000project02template.Rmd` file.
```

##### 5. Create a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`, and display the plot using a code chunk. Make sure the code used to generate the plot is hidden. Include a descriptive caption for the image.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [plotting in r](https://thedatamine.github.io/the-examples-book/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- Code chunk under (5) that creates and displays a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`.
```

##### 6. Insert the following code chunk under (5) in `stat29000project02template.Rmd`. Try knitting the document. Something should go wrong. Fix the problem and knit again. If another problem appears, fix it. What was the first problem? What was the second problem?
       
````markdown
`r ''````{r install-packages}
plot(my_variable)
```
````

**Hint:** *Take a close look at the name we give our code chunk.*

**Hint:** *Take a look at the code chunk where `my_variable` is declared.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- The modified version of the inserted code that fixes both problems.
- A sentence explaining what the first problem was.
- A sentence explaining what the second problem was.
```

---

### Project 4

---

**Motivation:** The need to search files and datasets based on the text held within is common during various parts of the data wrangling process. `grep` is an extremely powerful UNIX tool that allows you to do so using regular expressions. Regular expressions are a structured method for searching for specified patterns. Regular expressions can be very complicated, [even professionals can make critical mistakes](https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/). With that being said, learning some of the basics is an incredible tool that will come in handy regardless of the language you are working in.

**Context:** We've just begun to learn the basics of navigating a file system in UNIX using various terminal commands. Now we will go into more depth with one of the most useful command line tools, `grep`, and experiment with regular expressions using `grep`, R, and later on, Python.

**Scope:** grep, regular expression basics, utilizing regular expression tools in R and Python

**Learning objectives:**

```{block, type="bbox"}
- Use `grep` to search for patterns within a dataset.
- Use `cut` to section off and slice up data from the command line.
- Use `wc` to count the number of lines of input.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/movies_and_tv/the_office_dialogue.csv`

A public sample of the data can be found here: [the_office_dialogue.csv](https://www.datadepot.rcac.purdue.edu/datamine/movies-and-tv/the_office_dialogue.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

`grep` stands for (g)lobally search for a (r)egular (e)xpression and (p)rint matching lines. As such, to best demonstrate `grep`, we will be using it with textual data. You can read about and see examples of `grep` [here](https://thedatamine.github.io/the-examples-book/unix.html#grep).

##### 1. Login to Scholar and use `grep` to find the dataset we will use this project. The dataset we will use is the only dataset to have the text "bears. beets. battlestar galactica.". What is the name of the dataset and where is it located?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The `grep` command used to find the dataset.
- The name and location in Scholar of the dataset.
- Use `grep` and `grepl` within R to solve a data-driven problem.
```

##### 2. `grep` prints the line that the text you are searching for appears in. In project 3 we learned a UNIX command to quickly print the first _n_ lines from a file. Use this command to get the headers for the dataset. As you can see, each line in the tv show is a row in the dataset. You can count to see which column the various bits of data live in.

Write a line of UNIX commands that searches for "bears. beets. battlestar galactica." and, rather than printing the entire line, prints only the character who speaks the line, as well as the line itself.

**Hint:** *The result if you were to search for "bears. beets. battlestar galactica." should be:*

```{txt}
"Jim","Fact. Bears eat beets. Bears. Beets. Battlestar Galactica."
```

**Hint:** *One method to solve this problem would be to [pipe](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection) the output from `grep` to [`cut`](https://thedatamine.github.io/the-examples-book/unix.html#cut).*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to perform the operation.
```

##### 3. This particular dataset happens to be very small. You could imagine a scenario where the file is many gigabytes and not easy to load completely into R or Python. We are interested in learning what makes Jim and Pam tick as a couple. Use a line of UNIX commands to create a new dataset called `jim_and_pam.csv`. Include only lines that are spoken by either Jim or Pam, or reference Jim or Pam in any way. Include only the following columns: `episode_name`, `character`, `text`, `text_w_direction`, and `air_date`. How many rows of data are in the new file? How many megabytes is the new file (to the nearest 1/10th of a megabyte)?

**Hint:** *[Redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection).*

**Hint:** *It is OK if you get an erroneous line where the word "jim" or "pam" appears as a part of another word.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [ls](https://thedatamine.github.io/the-examples-book/unix.html#ls), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to create the new file. 
- The number of rows of data in the new file, and the accompanying UNIX command used to find this out.
- The number of megabytes (to the nearest 1/10th of a megabyte) that the new file has, and the accompanying UNIX command used to find this out.
```

##### 4. Find all lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark. Use only 1 "!" within your regular expression. How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command(s) used to solve this problem.
- The number of lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark.
```

##### 5. Find all lines that contain the text "that's what" followed by any amount of any text and then "said". How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command used to solve this problem.
- The number of lines that contain the text "that's what" followed by any amount of text and then "said".
```

Regular expressions are really a useful semi language-agnostic tool. What this means is regardless of the programming language your are using, there will be some package that allows you to use regular expressions. In fact, we can use them in both R and Python! This can be particularly useful when dealing with strings. Load up the dataset you discovered in (1) using `read.csv`. Name the resulting data.frame `dat`.

##### 6. The `text_w_direction` column in `dat` contains the characters' lines with inserted direction that helps characters know what to do as they are reciting the lines. Direction is shown between square brackets "[" "]". Create a new column called `has_direction` that is set to `TRUE` if the `text_w_direction` column has direction, and `FALSE` otherwise. Use regular expressions and the `grepl` function in R to accomplish this.

**Hint:** *Make sure all opening brackets "[" have a corresponding closing bracket "]".*

**Hint:** *Think of the pattern as any line that has a [, followed by any amount of any text, followed by a ], followed by any amount of any text.*

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [grepl](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

##### 7. Modify your regular expression in (7) to find lines with 2 or more sets of direction.

For example, the following line has 2 directions: `dat$text_w_direction[2789]`. How many lines have more than 2 directions? How many have more than 5?

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In (6), your solution may have found a match in both lines. In this question we want it to find only lines with 2+ directions, so the first line would not be a match.

**Relevant topics:** *[length](#r-length), [grep](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
- How many lines have > 2 directions?
- How many lines have > 5 directions?
```

##### 8. Use the `str_extract_all` function from the `stringr` package to extract the direction(s) as well as the text between direction(s) from each line. Put the strings in a new column called `direction`.

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In this question, your solution may have extracted:

```{txt}
[emphasize this]
[emphasize this] 2 sets of direction, do you see the difference [shrug]
```

This is ok.

**Note:** *If you capture text between two sets of direction, this is ok. For example, if we capture "[this] is a [test]" from "if we capture [this] is a [test]", this is ok.*

**Relevant topics:** *[str_extract_all](#r-str-extract)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

---

### Project 5

---

**Motivation:** Becoming comfortable stringing together commands and getting used to navigating files in a terminal is important for every data scientist to do. By learning the basics of a few useful tools, you will have the ability to quickly understand and manipulate files in a way which is just not possible using tools like Microsoft Office, Google Sheets, etc.

**Context:** We've been using UNIX tools in a terminal to solve a variety of problems. In this project we will continue to solve problems by combining a variety of tools using a form of redirection called piping.

**Scope:** grep, regular expression basics, UNIX utilities, redirection, piping

**Learning objectives:**

```{block, type="bbox"}
- Use `cut` to section off and slice up data from the command line.
- Use piping to string UNIX commands together.
- Use `sort` and it's options to sort data in different ways.
- Use `head` to isolate _n_ lines of output.
- Use `wc` to summarize the number of lines in a file or in output.
- Use `uniq` to filter out non-unique lines.
- Use `grep` to search files effectively.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/amazon/amazon_fine_food_reviews.csv`

A public sample of the data can be found here: [amazon_fine_food_reviews.csv](https://www.datadepot.rcac.purdue.edu/datamine/amazon/amazon_fine_food_reviews.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

#### Questions

##### 1. What is the `Id` of the most helpful review if we consider the review with highest `HelpfulnessNumerator` to be an indicator of helpfulness (higher is more helpful)?

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
- The `Id` of the most helpful review.
```

##### 2. What proportion of all `Summary`s are unique? Use two lines of UNIX commands to find the answer.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Two lines of UNIX commands used to solve the problem.
- The ratio of unique `Summary`'s.
```

##### 3. Use a simple UNIX command to create a frequency table of `Score`.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 4. Who is the user with the highest number of reviews? There are two columns you could use to answer this question, but which column do you think would be most appropriate and why?

**Hint:** *You may need to pipe the output to `sort` multiple times.*

**Hint:** *To create the frequency table, read through the `man` pages for `uniq`. Man pages are the "manual" pages for UNIX commands. You can read through the man pages for uniq by running the following:*

```{bash, eval=F}
man uniq
```

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection), [man](https://thedatamine.github.io/the-examples-book/unix.html#man)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 5. Anecdotally, there seems to be a tendency to leave reviews when we feel strongly (either positive or negative) about a product. For the user with the highest number of reviews, would you say that they follow this pattern of extremes? Let's consider 5 star reviews to be strongly positive and 1 star reviews to be strongly negative. Let's consider anything in between neither strongly positive nor negative.

**Hint:** *You may find the solution to problem (3) useful.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 6. We want to compare the most helpful review with a `Score` of 5 with the most helpful review with a `Score` of 1. Use UNIX commands to calculate these values. Write down the `ProductId` of both reviews. In the case of a tie, write down all `ProductId`'s to get full credit. In this case we are considering the most helpful review to be the review with the highest `HelpfulnessNumerator`.

**Hint:** *You can use multiple lines to solve this problem.*

**Relevant topics:** *[sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The lines of UNIX commands used to solve the problem.
- `ProductId`'s of both requested reviews.
```

##### 7. Using the `ProductId`'s from the previous question, create a new dataset called `reviews.csv` which contains the `ProductId`'s and `Score` of all reviews with the corresponding `ProductId`'s. 

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#head), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 8. Use R to load up `reviews.csv` into a new data.frame called `dat`. Create a histogram for each products' `Score`. Compare the most helpful review `Score` with the `Score`'s given in the histogram. Based on this comparison, decide (anecdotally) whether you think people found the review helpful because the product is overrated, underrated, or correctly reviewed by the masses.

**Relevant topics:** *[read.csv](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-reading-and-writing-data), [hist](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- R code used to create the histograms.
- 3 histograms, 1 for each `ProductId`.
- 1-2 sentences explaining whether or not you think people found the review helpful because the produce is overrated, underrated, or correctly reviewed, and why.
```

---

### Project 6

---

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
```

#### Dataset: `/class/datamine/data/flights/subset/YYYY.csv` 
(e.g. for 1987, `/class/datamine/data/flights/subset/1987.csv`)

**Public:** https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/YYYY.csv (e.g. for 1987, https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv)

#### Questions 

#### 1. In previous projects we learned how to get a single column of data from a csv file. Write 1 line of UNIX commands to print the 17th column, the `Origin`, from `1987.csv`. Write another line, this time using `awk` to do the same thing. Which one do you prefer, and why?

**Relevant topics:** [cut](#cut), [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- One line of UNIX commands to solve the problem *without* using `awk`.
- One line of UNIX commands to solve the problem using `awk`.
- 1-2 sentences describing which method you prefer and why.
```

#### 2. Write a bash script that accepts a year (1987, 1988, etc.) and a column *n* and returns the *nth* column of the associated year of data.

**Relevant topics:** awk, bash scripts

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
```

#### 3. How many flights came into Indianapolis (IND) in 2008? First solve this problem without using `awk`, then solve this problem using *only* `awk`.

**Relevant topics:** cut, grep, wc, awk, piping

```{block, type="bbox"}
**Item(s) to submit:** 

- One line of UNIX commands to solve the problem *without* using `awk`.
- One line of  UNIX commands to solve the problem using `awk`. 
- The number of flights that came into Indianapolis (IND) in 2008.
```

#### 4. Do you expect the number of unique origins and destinations to be the same? Find out using any command line tool you'd like. Are they indeed the same? How many unique values do we have per category (`Origin`, `Dest`)?

**Relevant topics:** cut, sort, uniq, wc, awk

```{block, type="bbox"}
**Item(s) to submit:**

- 1-2 sentences explaining whether or not you expect the number of unique origins and destinations to be the same.
- The UNIX command(s) used to figure out if the number of unique origins and destinations are the same. 
- The number of unique values per category (`Origin`, `Dest`).
```

#### 5. In (4) we found that there are not the same number of unique `Origin`'s as `Dest`'s. Find the IATA airport code for all `Origin`'s that dont appear in a `Dest` and all `Dest`'s that don't appear in an `Origin`.

*Hint:* https://www.tutorialspoint.com/unix_commands/comm.html

**Relevant topics:** comm, cut, sort, uniq, redirection

```{block, type="bbox"}
**Item(s) to submit:**

- The line(s) of UNIX command(s) used to answer the question.
- The list of `Origin`s that don't appear in `Dest`.
- The list of `Dest`s that don't appear in `Origin`.
```


#### 6. What was the average number of flights in 2008 per unique `Origin` with the `Dest` of "IND"? How does "PHX" (as a unique `Origin`) compare to the average?

*Hint:* You manually do the average calculation by dividing the result from (3) by the number of unique `Origin`'s that have a `Dest` of "IND".

**Relevant topics:** awk, sort, grep, wc

```{block, type="bbox"}
**Item(s) to submit:**

- The average number of flights in 2008 per unique `Origin` with the `Dest` of "IND".
- 1-2 sentences explaining how "PHX" compares (as a unique `Origin`) to the average?
```

#### 7. Write a bash script that takes a year and IATA airport code and returns the year, and the total number of flights to and from the given airport. Example rows may look like:

```{txt, eval=F}
1987, 12345
1988, 44
```

Run the script with inputs: `1991` and `ORD`. Include the output in your submission.

**Relevant topics:** bash scripts, cut, piping, grep, wc

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The output of the script given `1991` and `ORD` as inputs.
```

---

### Project 7

---

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
```

#### Dataset: 

The following questions will use the dataset found in Scholar:
`/class/datamine/data/flights/subset/YYYY.csv` 

An example of the data for the year 1987 can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv).

Sometimes if you are about to dig into a dataset, it is good to quickly do some sanity checks early on to make sure the data is what you expect it to be. 

##### 1. Write a line of code that prints a list of the unique values in the `DayOfWeek` column. Write a line of code that prints a list of the unique values in the `DayOfMonth` column. Write a line of code that prints a list of the unique values in the `Month` column. Use the `1987.csv` dataset. Are the results what you expected?

**Relevant topics:** [cut](#cut), [sort](#sort)

```{block, type="bbox"}
**Item(s) to submit:**

- 3 lines of code used to get a list of unique values for the chosen columns.
- 1-2 sentences explaining whether or not the results are what you expected.
```

##### 2. Our files should have 29 columns. Write a line of code that prints any lines in a file that do *not* have 29 columns. Test it on `1987.csv`, were there any rows without 29 columns?

**Relevant topics:** [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- Line of code used to solve the problem.
- 1-2 sentences explaining whether or not there were any rows without 29 columns.
```

##### 3. Write a bash script that, given a "begin" year and "end" year, cycles through the associated files and prints any lines that do *not* have 29 columns.

**Relevant topics:** [awk](#awk), [bash scripts](#writing-scripts)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The results of running your bash scripts from year 1987 to 2008.
```

##### 4. `awk` is a really good tool to quickly get some data and manipulate it a little bit. For example, let's see the number of kilometers and miles traveled in 1990. To convert from miles to kilometers, simply multiply by 1.609344. 

**Example output:**

```{txt, eval=F}
Miles: 12345
Kilometers: 19867.35168
```

**Relevant topics:** [awk](#awk), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem. 
- The results of running the code.
```

##### 5. Use `awk` to calculate the number of `DepDelay` minutes by `DayOfWeek`. Use `2007.csv`.

**Example output:**

```{txt, eval=F}
DayOfWeek:  0
1:  1234567
2:  1234567
3:  1234567
4:  1234567
5:  1234567
6:  1234567
7:  1234567
```

**Note:** 1 is Monday.

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

##### 6. It wouldn't be fair to compare the total `DepDelay` minutes by `DayOfWeek` as the number of flights may vary. One way to take this into account is to instead calculate an average. Modify (5) to calculate the average number of `DepDelay` minutes by the number of flights per `DayOfWeek`. Use `2007.csv`.

**Example output:**

```{txt, eval=F}
DayOfWeek:  0
1:  1.234567
2:  1.234567
3:  1.234567
4:  1.234567
5:  1.234567
6:  1.234567
7:  1.234567
```

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
```

##### 7. As a quick follow-up, _slightly_ modify (6) to perform the same calculation for `ArrDelay`. Do the `ArrDelay`s and `DepDelay`s appear to have the highest delays on the same day? Use `2007.csv`.

**Example output:**

```{txt, eval=F}
DayOfWeek:  0
1:  1.234567
2:  1.234567
3:  1.234567
4:  1.234567
5:  1.234567
6:  1.234567
7:  1.234567
```

**Relevant topics:** [awk](#awk), [sort](#sort), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The code used to solve the problem.
- The output from running the code.
- 1-2 sentences explaining whether or not the `ArrDelay`s and `DepDelay`s appear to have the highest delays on the same day.
```

---

### Project 8

---

## STAT 39000

### Project 1

--- 

**Motivation:** In this project we will jump right into an R review. In this project we are going to break one larger data-wrangling problem into discrete parts. There is a slight emphasis on writing functions and dealing with strings. At the end of this project we will have greatly simplified a dataset, making it easy to dig into.

**Context:** We just started the semester and are digging into a large dataset, and in doing so, reviewing R concepts we've previously learned.

**Scope:** data wrangling in R, functions

**Learning objectives:**

#### Dataset: 

`/class/datamine/data/airbnb`

Public: ???

Often times (maybe even the majority of the time) data doesn’t come in one nice file or database. Explore the dataset in `/class/datamine/data/airbnb`.

##### 1. You may have noted that, for each country, city, and date we can find 3 files: `calendar.csv.gz`, `listings.csv.gz`, and `reviews.csv.gz` (for now, we will ignore all files in the "visualisations" folders). Let's take a look at the data in each of the three types of files. Pick a country, city and date, and read the first 50 rows of each of the 3 datasets. Provide 1-2 sentences explaining the type of information found in each, and what variable(s) could be used to join them. 

**Hint:** `read.csv` has an argument to select the number of rows we want to read.

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code used to read the first 50 rows of each dataset.
- 1-2 sentences briefly describing the information contained in each dataset.
- Name(s) of variable(s) that could be used to join them.
```

To read a compressed csv, simply use the `read.csv` function:

```{r, eval=F}
dat <- read.csv("/class/datamine/data/airbnb/brazil/rj/rio-de-janeiro/2019-06-19/data/calendar.csv.gz")
head(dat)
```

Let's work towards getting this data into an easier format to analyze. From now on, we will focus on the `listings.csv.gz` datasets.

##### 2. Write a function called `get_paths_for_country`, that, given a string with the country name, returns a vector with the full paths for all `listings.csv.gz` files, starting with `/class/datamine/data/airbnb/...`.

Some example output from `get_paths_for_country("united-states")`:

```{txt}
 [1] "/class/datamine/data/airbnb/united-states/ca/los-angeles/2019-07-08/data/listings.csv.gz"       
 [2] "/class/datamine/data/airbnb/united-states/ca/oakland/2019-07-13/data/listings.csv.gz"           
 [3] "/class/datamine/data/airbnb/united-states/ca/pacific-grove/2019-07-01/data/listings.csv.gz"     
 [4] "/class/datamine/data/airbnb/united-states/ca/san-diego/2019-07-14/data/listings.csv.gz"         
 [5] "/class/datamine/data/airbnb/united-states/ca/san-francisco/2019-07-08/data/listings.csv.gz"     
```

**Hint:** `list.files` is useful with the `recursive=T` option.

**Hint:** To exclude "visualisations" folders, try: `grep("visualisations", ..., invert=T)`.

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code for your `get_paths_for_country` function.
```

##### 3. Write a function called `get_data_for_country` that, given a string with the country name, returns a data.frames containing the all listings data for that country. Use your previously written function to help you. 

**Hint:** Use `stringAsFactors=F` in the `read.csv` function.

**Hint:** Use `do.call(rbind, <listofdataframes>)` to combine a list of dataframes into a single dataframe.

**Relevant topics:** rbind, [lapply](#r-lapply), [function](#r-basic-functions)

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code for your `get_data_for_country` function.
```

##### 4. Use your `get_data_for_country` to get the data for a country of your choice, and make sure to name the data.frame `listings`. Take a look at the following columns: `host_is_superhost`, `host_has_profile_pic`, `host_identity_verified`, and  `is_location_exact`. What is the data type for each column? Is there a more appropriate type for them? If so, which type would you recommend? 

**Hint:** Remember, there are a six types of vectors: logical, integer, double, character, complex, and raw. To see the vector data types of you can use `typeof` or `str`. The function `typeof` will return the type, while `str` will return more information. See some examples below:

```{r, eval=T}
# Using typeof
typeof(letters)
typeof(1:10)
```

```{r, eval=T}
# Using str
str(letters)
str(1:10)
```

##### 5. Write a function called `transform_column` that, given a column similar to the ones in (4) (more or less, lowercase "t"s and "f"s) transforms it to your suggested vector type in (4). Note that NA values for these columns appear as blank (`""`), and we need to be careful when transforming the data. Test your function on column `host_is_superhost`.

**Relevant topics:** toupper, as.logical

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code for your `transform_column` function.
- Type of `transform_column(listings$host_is_superhost)`.
```

##### 6. Before we can use your function, we need to determine which columns are similar to `host_is_superhost` (i.e., lowercase "t"s and "f"s) and need transformation. Create a function named `should_be_transformed` that, given a column, determines (returns `TRUE` or `FALSE`) if it contains only "t", "f", and "" values. Use your newly created function to create a vector named `columns_to_transform` which contains all columns we want to transform using the function in (5). How many columns are in this format?

**Relevant topics:** unique, %in%, any, [sapply](#r-sapply), which

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code for your `should_be_transformed` function.
- Chunk of code used to obtain `columns_to_transform`.
```

##### 7. Apply your function `transform_column` to all columns in `columns_to_transform` in your `listings` data. Make sure it worked by checking the type of columns `id` and `instant_bookable`. Note that the column `id` should have the same type as before.

**Relevant topics:** [apply](#r-apply)

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code to get your new `listings` data.
- Type of columns `id` and `instant_bookable`.
```

##### 8. Now that we have organized and cleaned our data, let's explore it! Based on your `listings` data, if you are looking at an instant bookable listing (where `instant_bookable` is `TRUE`), would you expect the location to be exact (where `is_exact_location` is `TRUE`)? Why or why not?

**Hint:** Make a frequency table, and see how many instant bookable listings have exact location.

**Relevant topics:** table

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code to get a frequency table.
- 1-2 sentences explaining whether or not we would expect the location to be exact if we were looking at a instant bookable listing.
```

##### 9. Create a histogram for response rates (`host_response_rate`) for super hosts (where `host_is_superhost` is `TRUE`). If your listings do not contain any super hosts, load data from a different country. Note that we first need to convert `host_response_rate` from a character containing "%" signs to a numeric variable.

**Relevant topics:** gsub, as.numeric

```{block, type="bbox"}
**Item(s) to submit:**

- Chunk of code used to answer the question.
- Histogram of response rates for super hosts.
```

--- 

### Project 2

---

**Motivation:** The ability to quickly reproduce an analysis is important. It is often necessary that other individuals will need to be able to understand and reproduce an analysis. This concept is so important there are classes solely on reproducible research! In fact, there are papers that investigate and highlight the lack of reproducibility in various fields. If you are interested in reading about this topic, a good place to start is the paper titled ["Why Most Published Research Findings Are False"](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124), by John Ioannidis (2005). 

**Context:** Making your work reproducible is extremely important. We will focus on the computational part of reproducibility. We will learn RMarkdown to document your analyses so others can easily understand and reproduce the computations that led to your conclusions. Pay close attention as future project templates will be RMarkdown templates.

**Scope:** Understand Markdown, RMarkdown, and how to use it to make your data analysis reproducible.

**Learning objectives:**

```{block, type="bbox"}
- Use Markdown syntax within an Rmarkdown document to achieve various text transformations.
- Use RMarkdown code chunks to display and/or run snippets of code.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

##### 1. Make the following text (including the asterisks) bold: `This needs to be **very** bold`. Make the following text (including the underscores) italicized: `This needs to be _very_ italicized.`

**Hint:** *Try mixing and matching ways to embolden or italicize text. Alternatively, look up "escaping characters in markdown", or see [here](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters).*

**Hint:** *Be sure to check out the [Rmarkdown Cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) and our section on [Rmarkdown in the book](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown).*

**Note:** *Rmarkdown is essentially Markdown + the ability to run and display code chunks. In this question, we are actually using Markdown within Rmarkdown!*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [escaping characters](https://thedatamine.github.io/the-examples-book/faqs.html#escape-characters)*

```{block, type="bbox"}
**Item(s) to submit:**

- Fill in the chunk under (1) in the `stat29000project02template.Rmd` file with 2 lines of markdown text. Note that when compiled, this text will be unmodified, regular text.
```

##### 2. Create an unordered list of your top 3 favorite academic interests (some examples could include: machine learning, operating systems, forensic accounting, etc.). Create another *ordered* list that ranks your academic interests in order of most interested to least interested.

**Hint:** *You can learn what ordered and unordered lists are [here]( https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf).*

**Note:** *Similar to (1a), in this question we are dealing with Markdown. If we were to copy and paste the solution to this problem in a Markdown editor, it would be the same result as when we Knit it here.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the lists under (2) in the `stat29000project02template.Rmd` file. Note that when compiled, this text will appear as nice, formatted lists.
```

##### 3. Browse https://www.linkedin.com/ and read some profiles. Pay special attention to accounts with an "About" section. Write your own personal "About" section using Markdown. Include the following:

- A header (your choice of size) that says "About".
- A horizontal rule directly underlining the header.
- The text of your personal "About" section that you would feel comfortable uploading to linkedin, including at least 1 link.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Create the described profile under (3) in the `stat29000project02template.Rmd` file.
```

##### 4. LaTeX is a powerful editing tool where you can create beautifully formatted equations and formulas. Replicate the equation found [here](https://wikimedia.org/api/rest_v1/media/math/render/svg/87c061fe1c7430a5201eef3fa50f9d00eac78810) as closely as possible.

**Hint:** *Lookup "latex mid" and "latex frac".*

```{block, type="bbox"}
**Item(s) to submit:**

- Replicate the equation using LaTeX under (1d) in the `stat39000project02template.Rmd` file.
```

##### 5. Your co-worker wrote a report, and has asked you to beautify it. Knowing Rmarkdown, you agreed. Spruce up the report found under (4) in `stat29000project02template.Rmd`. At a minimum:

- Make the title pronounced.
- Make all links appear as a word or words, rather than the long-form URL.
- Organize all code into code chunks where code and output are displayed. If the output is really long, just display the code.
- Make the calls to the `library` function and the `install.packages` function be evaluated but not displayed. Make sure all warnings and errors that may eventually occur, do not appear in the final document.

Feel free to make any other changes that make the report more visually pleasing.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- Spruce up the "document" under (4) in the `stat29000project02template.Rmd` file.
```

#### 6. Create a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`, and display the plot using a code chunk. Make sure the code used to generate the plot is hidden. Include a descriptive caption for the image.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown), [plotting in r](https://thedatamine.github.io/the-examples-book/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- Code chunk under (5) that creates and displays a plot using a built-in dataset like `iris`, `mtcars`, or `Titanic`.
```

##### 7. Insert the following code chunk under (5) in `stat29000project02template.Rmd`. Try knitting the document. Something should go wrong. Fix the problem and knit again. If another problem appears, fix it. What was the first problem? What was the second problem?
       
````markdown
`r ''````{r install-packages}
plot(my_variable)
```
````

**Hint:** *Take a close look at the name we give our code chunk.*

**Hint:** *Take a look at the code chunk where `my_variable` is declared.*

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- The modified version of the inserted code that fixes both problems.
- A sentence explaining what the first problem was.
- A sentence explaining what the second problem was.
```

##### 8. RMarkdown is also an excellent tool to create a slide deck. Use the information [here](https://rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf) or [here](https://thedatamine.github.io/the-examples-book/r.html#how-do-i-create-a-set-of-slides-using-rmarkdown) to convert your solutions into a slide deck rather than the regular PDF. You may use `slidy`, `ioslides` or `beamer`. Make any needed modifications to make the solutions knit into a well-organized slide deck. Modify (2) so the bullets are incrementally presented as the slides progresses.

**Relevant topics:** *[rmarkdown](https://thedatamine.github.io/the-examples-book/r.html#r-rmarkdown)*

```{block, type="bbox"}
**Item(s) to submit:**

- The modified version of the inserted code that fixes both problems.
- A sentence explaining what the first problem was.
- A sentence explaining what the second problem was.
```

---

### Project 4

---

**Motivation:** The need to search files and datasets based on the text held within is common during various parts of the data wrangling process. `grep` is an extremely powerful UNIX tool that allows you to do so using regular expressions. Regular expressions are a structured method for searching for specified patterns. Regular expressions can be very complicated, [even professionals can make critical mistakes](https://blog.cloudflare.com/details-of-the-cloudflare-outage-on-july-2-2019/). With that being said, learning some of the basics is an incredible tool that will come in handy regardless of the language you are working in.

**Context:** We've just begun to learn the basics of navigating a file system in UNIX using various terminal commands. Now we will go into more depth with one of the most useful command line tools, `grep`, and experiment with regular expressions using `grep`, R, and later on, Python.

**Scope:** grep, regular expression basics, utilizing regular expression tools in R and Python

**Learning objectives:**

```{block, type="bbox"}
- Use `grep` to search for patterns within a dataset.
- Use `cut` to section off and slice up data from the command line.
- Use `wc` to count the number of lines of input.
```


You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/movies_and_tv/the_office_dialogue.csv`

A public sample of the data can be found here: [the_office_dialogue.csv](https://www.datadepot.rcac.purdue.edu/datamine/movies-and-tv/the_office_dialogue.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

`grep` stands for (g)lobally search for a (r)egular (e)xpression and (p)rint matching lines. As such, to best demonstrate `grep`, we will be using it with textual data. You can read about and see examples of `grep` [here](https://thedatamine.github.io/the-examples-book/unix.html#grep).

##### 1. Login to Scholar and use `grep` to find the dataset we will use this project. The dataset we will use is the only dataset to have the text "bears. beets. battlestar galactica.". What is the name of the dataset and where is it located?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The `grep` command used to find the dataset.
- The name and location in Scholar of the dataset.
- Use `grep` and `grepl` within R to solve a data-driven problem.
```

##### 2. `grep` prints the line that the text you are searching for appears in. In project 3 we learned a UNIX command to quickly print the first _n_ lines from a file. Use this command to get the headers for the dataset. As you can see, each line in the tv show is a row in the dataset. You can count to see which column the various bits of data live in.

Write a line of UNIX commands that searches for "bears. beets. battlestar galactica." and, rather than printing the entire line, prints only the character who speaks the line, as well as the line itself.

**Hint:** *The result if you were to search for "bears. beets. battlestar galactica." should be:*

```{txt}
"Jim","Fact. Bears eat beets. Bears. Beets. Battlestar Galactica."
```

**Hint:** *One method to solve this problem would be to [pipe](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection) the output from `grep` to [`cut`](https://thedatamine.github.io/the-examples-book/unix.html#cut).*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to perform the operation.
```

##### 3. This particular dataset happens to be very small. You could imagine a scenario where the file is many gigabytes and not easy to load completely into R or Python. We are interested in learning what makes Jim and Pam tick as a couple. Use a line of UNIX commands to create a new dataset called `jim_and_pam.csv`. Include only lines that are spoken by either Jim or Pam, or reference Jim or Pam in any way. Include only the following columns: `episode_name`, `character`, `text`, `text_w_direction`, and `air_date`. How many rows of data are in the new file? How many megabytes is the new file (to the nearest 1/10th of a megabyte)?

**Hint:** *[Redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection).*

**Hint:** *It is OK if you get an erroneous line where the word "jim" or "pam" appears as a part of another word.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [ls](https://thedatamine.github.io/the-examples-book/unix.html#ls), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to create the new file. 
- The number of rows of data in the new file, and the accompanying UNIX command used to find this out.
- The number of megabytes (to the nearest 1/10th of a megabyte) that the new file has, and the accompanying UNIX command used to find this out.
```

##### 4. Find all lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark. Use only 1 "!" within your regular expression. How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command(s) used to solve this problem.
- The number of lines where either Jim/Pam/Michael/Dwight's name is followed by an exclamation mark.
```

##### 5. Find all lines that contain the text "that's what" followed by any amount of any text and then "said". How many lines are there?

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command used to solve this problem.
- The number of lines that contain the text "that's what" followed by any amount of text and then "said".
```

##### 6. Find all of the lines where Pam is called "Beesley" instead of "Pam" or "Pam Beesley".

**Hint:** *A negative lookbehind would be one way to solve this.*

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The UNIX command used to solve this problem.
```

Regular expressions are really a useful semi language-agnostic tool. What this means is regardless of the programming language your are using, there will be some package that allows you to use regular expressions. In fact, we can use them in both R and Python! This can be particularly useful when dealing with strings. Load up the dataset you discovered in (1) using `read.csv`. Name the resulting data.frame `dat`.

##### 7. The `text_w_direction` column in `dat` contains the characters' lines with inserted direction that helps characters know what to do as they are reciting the lines. Direction is shown between square brackets "[" "]". Create a new column called `has_direction` that is set to `TRUE` if the `text_w_direction` column has direction, and `FALSE` otherwise. Use regular expressions and the `grepl` function in R to accomplish this.

**Hint:** *Make sure all opening brackets "[" have a corresponding closing bracket "]".*

**Hint:** *Think of the pattern as any line that has a [, followed by any amount of any text, followed by a ], followed by any amount of any text.*

**Relevant topics:** *[grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [grepl](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

##### 8. Modify your regular expression in (7) to find lines with 2 or more sets of direction.

For example, the following line has 2 directions: `dat$text_w_direction[2789]`. How many lines have more than 2 directions? How many have more than 5?

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In (7), your solution may have found a match in both lines. In this question we want it to find only lines with 2+ directions, so the first line would not be a match.

**Relevant topics:** *[length](#r-length), [grep](#r-grep)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
- How many lines have > 2 directions?
- How many lines have > 5 directions?
```

##### 9. Use the `str_extract_all` function from the `stringr` package to extract the direction(s) as well as the text between direction(s) from each line. Put the strings in a new column called `direction`.

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In this question, your solution may have extracted:

```{txt}
[emphasize this]
[emphasize this] 2 sets of direction, do you see the difference [shrug]
```

This is ok.

**Note:** *If you capture text between two sets of direction, this is ok. For example, if we capture "[this] is a [test]" from "if we capture [this] is a [test]", this is ok.*

**Relevant topics:** *[str_extract_all](#r-str-extract)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

##### 10. Repeat (9) but this time make sure you only capture the brackets and text within the brackets. Save the results in a new column called `direction_correct`. You can test to see if it is working by running the following code:

```{r, eval=F}
dat$direction_correct[747]
```

```{txt}
This is a line with [emphasize this] only 1 direction!
This is a line with [emphasize this] 2 sets of direction, do you see the difference [shrug].
```

In (7), your solution may have extracted:

```{txt}
[emphasize this]
[emphasize this] 2 sets of direction, do you see the difference [shrug]
```

This is ok for (7). In this question, however, we want to fix this to only extract:

```{txt}
[emphasize this]
[emphasize this] [shrug]
```

**Hint:** *This regular expression will be hard to read.*

**Hint:** *The pattern we want is: literal opening bracket, followed by 0+ of any character other than the literal [ or literal ], followed by a literal closing bracket.*

**Relevant topics:** *[str_extract_all](#r-str-extract)*

```{block, type="bbox"}
**Item(s) to submit:**

- The R code used to solve this problem.
```

---

### Project 5

---

**Motivation:** Becoming comfortable stringing together commands and getting used to navigating files in a terminal is important for every data scientist to do. By learning the basics of a few useful tools, you will have the ability to quickly understand and manipulate files in a way which is just not possible using tools like Microsoft Office, Google Sheets, etc.

**Context:** We've been using UNIX tools in a terminal to solve a variety of problems. In this project we will continue to solve problems by combining a variety of tools using a form of redirection called piping.

**Scope:** grep, regular expression basics, UNIX utilities, redirection, piping

**Learning objectives:**

```{block, type="bbox"}
- Use `cut` to section off and slice up data from the command line.
- Use piping to string UNIX commands together.
- Use `sort` and it's options to sort data in different ways.
- Use `head` to isolate _n_ lines of output.
- Use `wc` to summarize the number of lines in a file or in output.
- Use `uniq` to filter out non-unique lines.
- Use `grep` to search files effectively.
```

You can find useful examples that walk you through relevant material in The Examples Book:

https://thedatamine.github.io/the-examples-book

It is highly recommended to read through, search, and explore these examples to help solve problems in this project.

**Important note:** It is highly recommended that you use https://rstudio.scholar.rcac.purdue.edu/. Simply click on the link and login using your Purdue account credentials. Use another system at your own risk. The version of RStudio on https://desktop.scholar.rcac.purdue.edu/ (which uses ThinLinc), is 99.9.9, and is known to have some strange issues when running code chunks.

Don't forget the very useful documentation shortcut `?`. To use, simply type `?` in the console, followed by the name of the function you are interested in. 

You can also look for package documentation by using `help(package=PACKAGENAME)`, so for example, to see the documentation for the package `ggplot2`, we could run:

```{r, eval=F}
help(package=ggplot2)
```

Sometimes it can be helpful to see the source code of a defined function. A [function](https://www.tutorialspoint.com/r/r_functions.htm) is any chunk of organized code that is used to perform an operation. Source code is the underlying `R` or `c` or `c++` code that is used to create the function. To see the source code of a defined function, type the function's name without the `()`. For example, if we were curious about what the function `Reduce` does, we could run:

```{r, eval=F}
Reduce
```

Occasionally this will be less useful as the resulting code will be code that calls `c` code we can't see. Other times it will allow you to understand the function better.

#### Dataset

The following questions will use the dataset found in Scholar:

`/class/datamine/data/amazon/amazon_fine_food_reviews.csv`

A public sample of the data can be found here: [amazon_fine_food_reviews.csv](https://www.datadepot.rcac.purdue.edu/datamine/amazon/amazon_fine_food_reviews.csv)

Answers to questions should all be answered using the full dataset located on Scholar. You may use the public samples of data to experiment with your solutions prior to running them using the full dataset.

#### Questions

##### 1. What is the `Id` of the most helpful review if we consider the review with highest `HelpfulnessNumerator` to be an indicator of helpfulness (higher is more helpful)?

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Line of UNIX commands used to solve the problem.
- The `Id` of the most helpful review.
```

##### 2. What proportion of all `Summary`s are unique? Use two lines of UNIX commands to find the answer.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [wc](https://thedatamine.github.io/the-examples-book/unix.html#wc), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- Two lines of UNIX commands used to solve the problem.
- The ratio of unique `Summary`'s.
```

##### 3. Use a simple UNIX command to create a frequency table of `Score`.

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 4. Who is the user with the highest number of reviews? There are two columns you could use to answer this question, but which column do you think would be most appropriate and why?

**Hint:** *You may need to pipe the output to `sort` multiple times.*

**Hint:** *To create the frequency table, read through the `man` pages for `uniq`. Man pages are the "manual" pages for UNIX commands. You can read through the man pages for uniq by running the following:*

```{bash, eval=F}
man uniq
```

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection), [man](https://thedatamine.github.io/the-examples-book/unix.html#man)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- The frequency table.
```

##### 5. Anecdotally, there seems to be a tendency to leave reviews when we feel strongly (either positive or negative) about a product. For the user with the highest number of reviews, would you say that they follow this pattern of extremes? Let's consider 5 star reviews to be strongly positive and 1 star reviews to be strongly negative. Let's consider anything in between neither strongly positive nor negative.

**Hint:** *You may find the solution to problem (3) useful.*

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [uniq](https://thedatamine.github.io/the-examples-book/unix.html#uniq), [sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [grep](https://thedatamine.github.io/the-examples-book/unix.html#grep), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 6. We want to compare the most helpful review with a `Score` of 5 with the most helpful review with a `Score` of 1. Use UNIX commands to calculate these values. Write down the `ProductId` of both reviews. In the case of a tie, write down all `ProductId`'s to get full credit. In this case we are considering the most helpful review to be the review with the highest `HelpfulnessNumerator`.

**Hint:** *You can use multiple lines to solve this problem.*

**Relevant topics:** *[sort](https://thedatamine.github.io/the-examples-book/unix.html#sort), [head](https://thedatamine.github.io/the-examples-book/unix.html#head), [piping](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The lines of UNIX commands used to solve the problem.
- `ProductId`'s of both requested reviews.
```

##### 7. Using the `ProductId`'s from the previous question, create a new dataset called `reviews.csv` which contains the `ProductId`'s and `Score` of all reviews with the corresponding `ProductId`'s.  

**Relevant topics:** *[cut](https://thedatamine.github.io/the-examples-book/unix.html#cut), [grep](https://thedatamine.github.io/the-examples-book/unix.html#head), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
```

##### 8. If we didn't use `cut` prior to searching for the `ProductId`'s in (7), we would get unwanted results. Modify the solution to (7) and explore. What is happening?

**Relevant topics:** *[cat](https://thedatamine.github.io/the-examples-book/unix.html#cat), [grep](https://thedatamine.github.io/the-examples-book/unix.html#head), [redirection](https://thedatamine.github.io/the-examples-book/unix.html#piping-and-redirection)*

```{block, type="bbox"}
**Item(s) to submit:**

- The line of UNIX commands used to solve the problem.
- 1-2 sentences explaining why we need to use `cut` first.
- 1-2 sentences explaining whether or not you think people found the review helpful because the produce is overrated, underrated, or correctly reviewed, and why.
```

##### 9. Use R to load up `reviews.csv` into a new data.frame called `dat`. Create a histogram for each products' `Score`. Compare the most helpful review `Score` with the `Score`'s given in the histogram. Based on this comparison, decide (anecdotally) whether you think people found the review helpful because the product is overrated, underrated, or correctly reviewed by the masses.

**Relevant topics:** *[read.csv](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-reading-and-writing-data), [hist](file:///Users/kamstut/Dropbox/work/datamine/the-examples-book/docs/r.html#r-plotting)*

```{block, type="bbox"}
**Item(s) to submit:**

- R code used to create the histograms.
- 3 histograms, 1 for each `ProductId`.
```

---

### Project 6

---

**Motivation:** A bash script is a powerful tool to perform repeated tasks. RCAC uses bash scripts to automate a variety of tasks. In fact, we use bash scripts on Scholar to do things like link Python kernels to your account, fix potential isues with Firefox, etc. `awk` is a programming language designed for text processing. The combination of these tools can be really powerful and useful for a variety of quick tasks.

**Context:** This is the first part in a series of projects that are designed to exercise skills around UNIX utilities, with a focus on writing bash scripts and `awk`. You will get the opportunity to manipulate data without leaving the terminal. At first it may seem overwhelming, however, with just a little practice you will be able to accomplish data wrangling tasks really efficiently. 

**Scope:** awk, UNIX utilities, bash scripts

**Learning objectives:**

```{block, type="bbox"}
- Use `awk` to process and manipulate textual data.
- Use piping and redirection within the terminal to pass around data between utilities.
- Use output created from the terminal to create a plot using R.
```

#### Dataset: 

The following questions will use the dataset found in Scholar:
`/class/datamine/data/flights/subset/YYYY.csv` 

An example of the data for the year 1987 can be found [here](https://www.datadepot.rcac.purdue.edu/datamine/flights/subset/1987.csv).

#### Questions

##### 1. In previous projects we learned how to get a single column of data from a csv file. Write 1 line of UNIX commands to print the 17th column, the `Origin`, from `1987.csv`. Write another line, this time using `awk` to do the same thing. Which one do you prefer, and why?

**Relevant topics:** [cut](#cut), [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- One line of UNIX commands to solve the problem _without_ using `awk`.
- One line of UNIX commands to solve the problem using `awk`.
- 1-2 sentences describing which method you prefer and why.
```

##### 2. Write a bash script that accepts a year (1987, 1988, etc.) and a column *n* and returns the *nth* column of the associated year of data.

**Relevant topics:** [awk](#awk), [bash scripts](#writing-scripts)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
```

##### 3. How many flights came into Indianapolis (IND) in 2008? First solve this problem without using `awk`, then solve this problem using *only* `awk`.

**Relevant topics:** [cut](#cut), [grep](#grep), [wc](#wc), [awk](#awk), [piping](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- One line of UNIX commands to solve the problem *without* using `awk`.
- One line of  UNIX commands to solve the problem using `awk`. 
- The number of flights that came into Indianapolis (IND) in 2008.
```

##### 4. Do you expect the number of unique origins and destinations to be the same? Find out using any command line tool you'd like. Are they indeed the same? How many unique values do we have per category (`Origin`, `Dest`)?

**Relevant topics:** [cut](#cut), [sort](#sort), [uniq](#uniq), [wc](#wc), [awk](#awk)

```{block, type="bbox"}
**Item(s) to submit:**

- 1-2 sentences explaining whether or not you expect the number of unique origins and destinations to be the same.
- The UNIX command(s) used to figure out if the number of unique origins and destinations are the same. 
- The number of unique values per category (`Origin`, `Dest`).
```

##### 5. In (4) we found that there are not the same number of unique `Origin`'s as `Dest`'s. Find the IATA airport code for all `Origin`'s that dont appear in a `Dest` and all `Dest`'s that don't appear in an `Origin`.

**Hint:** https://www.tutorialspoint.com/unix_commands/comm.htm

**Relevant topics:** [comm](#unix), [cut](#cut), [sort](#sort), [uniq](#uniq), [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The line(s) of UNIX command(s) used to answer the question.
- The list of `Origin`s that don't appear in `Dest`.
- The list of `Dest`s that don't appear in `Origin`.
```

##### 6. What was the average number of flights in 2008 per unique `Origin` with the `Dest` of "IND"? How does "PHX" (as a unique `Origin`) compare to the average?

**Hint:** You manually do the average calculation by dividing the result from (3) by the number of unique `Origin`'s that have a `Dest` of "IND".

**Relevant topics:** [awk](#awk), [sort](#sort), [grep](#grep), [wc](#wc)

```{block, type="bbox"}
**Item(s) to submit:**

- The average number of flights in 2008 per unique `Origin` with the `Dest` of "IND".
- 1-2 sentences explaining how "PHX" compares (as a unique `Origin`) to the average?
```

##### 7. Write a bash script that takes a year and IATA airport code and returns the year, and the total number of flights to and from the given airport. Example rows may look like:

```{txt, eval=F}
1987, 12345
1988, 44
```

Run the script with inputs: `1991` and `ORD`. Include the output in your submission.

**Relevant topics:** [bash scripts](#writing-scripts), [cut](#cut), [piping](#piping-and-redirection), [grep](#grep), [wc](#wc)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
- The output of the script given `1991` and `ORD` as inputs.
```

##### 8. Pick your favorite airport and get its IATA airport code. Write a bash script that, given the first year, last year, and airport code, runs the bash script from (7) for all years in the provided range for your given airport, or loops through all of the files for the given airport, appending all of the data to a new file called `my_airport.csv`.

**Relevant topics:** [bash scripts](#writing-scripts), [cut](#cut), [grep](#grep), [wc](#wc), for loops, echo, [redirection](#piping-and-redirection)

```{block, type="bbox"}
**Item(s) to submit:**

- The content of your bash script (starting with "#!/bin/bash") in a code chunk.
```

##### 9. In R, load `my_airport.csv` and create a line plot showing the year-by-year change. Label your x-axis "Year", your y-axis "Num Flights", and your title the name of the IATA airport code. Write 1-2 sentences with your observations.

**Relevant topics:** [read.csv](#r-reading-and-writing-data), lines

```{block, type="bbox"}
**Item(s) to submit:**

- Line chart showing year-by-year change in flights into and out of the chosen airport.
- R code used to create the chart.
- 1-2 sentences with your observations.
```

---

### Project 7

### Project 8
